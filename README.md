# 监控摄像头视频画面AI分析工具
### 写在开头：
**本工具所涉及代码完全使用Gemini AI生成，经反复试错修改后得到当前版本。因本人不具备充足的编程知识，故不能提供详细的技术支持，也不设置任何的著作权声明。任何人无需经过同意，即可随意下载、使用和修改本Repo的代码。**

---

### 本工具的设计目标：
1、在不使用NVIDIA GPU和CUDA的情况下，依赖Direct ML API在Windows环境下实现本地化AI图像分析。本Repo以AMD Radeon RX9070 16GB为例。

2、通过YOLO v8n模型，批量分析安防监控设备拍摄到的视频文件，从中截取存在人物、车辆活动的片段，并保存到指定目录，以期通过这种方式大幅减少分析监控画面所需的人力和时间成本，并尽可能避免遗漏。

3、借助FFmpeg的强大功能（FFmpeg管道流，Streaming Pipe）暴力解决部分品牌、型号的硬盘录像机所生成的视频文件不规范、导致Windows和部分第三方的视频播放器无法加载缩略图、无法正常打开和解码视频的问题。通过强行读取视频时长、FPS帧率和画面等信息，能够确保即使是不规范的视频文件，也可以正确解码并发送给AI进行分析。同时，在截取片段后，确保保存出来的结果是系统可以直接读取，无需再借助第三方工具进行解码的。

4、尽可能降低部署和运行的成本，并在代码中给足必要的注释，确保新手也能够轻松运行。

5、通过暴力方式强行解决Ultralytics始终倾向于使用CUDA或CPU进行运算，而不去调用Direct ML的问题。

---

### 本工具不适用于以下场景：
1、使用了NVIDIA GPU的设备。（不强制，即便是英伟达的显卡也可以跑Direct ML，但效率肯定不如专门优化的CUDA。你可以将本repo的链接整个喂给AI，让它帮你生成一个使用CUDA运行的方案。）

2、画面复杂多变、时常有人物车辆等活动的监控视频。本工具所使用的方案更倾向于固定角度的摄像头所拍摄的、大多数时候画面静止，或活动不频繁的视频文件分析，例如车库、花园、楼梯间等位置。因为代码的策略是只要检测到有活动就截取相应片段，并未指定特定的物体或人物，如果你的监控画面有人、物活动频繁，例如办公室、公路、超市，则截取后的视频片段可能不会和原文件有太大差别，这就失去了分析的意义。

3、完全不规范甚至加密的监控视频文件。极个别监控录像产品会使用私有格式编码和保存，若导出的视频文件不为FFmpeg能够直接解码的常见格式，例如mp4、avi、mkv、mov等，则本工具将完全不可用。你需要想办法将监控视频以常见的视频格式保存出来，再使用本工具进行分析。

---

### 推荐配置：
CPU：2014年后主流四核或以上CPU，至少能够确保软解1080P视频流畅的型号

RAM：16GB或以上

GPU：支持Direct ML API、显存大于等于4GB的显卡（YOLO v8n模型本身消耗的显存很少，大约在1-2GB。但如果你需要增加并发任务数，或换用更为精确的模型，则需要更大显存的支持）

硬盘：存放监控视频的硬盘推荐使用SSD固态硬盘（使用了USB3.0或以上的移动固态硬盘，或固态硬盘+USB3.0硬盘盒的方案也可），以确保并发任务流畅完成；保存截取片段的硬盘无要求

操作系统：Windows 10或以上，支持Python 3.11运行

---

### 部署方法：
1、前往 https://www.python.org/downloads/windows/ 下载并安装Windows版本的**Python 3.11.0**。不建议使用其他版本，否则安装依赖时极有可能会报错。若你的系统中已经安装了高版本的Python，请卸载或寻找指定Python版本运行的方式。

2、打开命令提示符（管理员），输入以下代码安装依赖：
```
pip install ultralytics onnxruntime-directml pandas moviepy
```

3、下载本Repo的exportmodel.py文件，通过命令提示符（管理员），执行以下命令：
```
python exportmodel.py
```
此时脚本会在C:\Users\用户名目录下生成yolov8n.pt和转换后的yolov8n.onnx模型文件。

4、下载本Repo的check.py文件，通过命令提示符（管理员），执行以下命令：
```
python check.py
```
若返回的结果中包含“DmlExecutionProvider”，则证明能够调用GPU进行处理。

5、下载本Repo的pipeline.py文件，使用记事本或其他代码编辑器打开并编辑部分内容：
```
# --- 核心参数配置 ---
SOURCE_DIR = r"H:\Videos"  # 你的视频源路径
SAVE_DIR = r"E:\process\clips"      # 结果保存路径
MODEL_PATH = "yolov8n.onnx"
NUM_PROCESSES = 6        # 并发进程数，5700X3D 建议 4-6 个进程，与下方STRIDE配合修改，STRIDE越大，运算压力越小，并发数可以越多
STRIDE = 10              # 跳帧数量，每隔多少帧分析一次，可适当增加以提高解析速度
IMG_SIZE = 1024          # 统一推理分辨率，中高端GPU推荐至少1024分辨率以提高分析精度
CONF_LEVEL = 0.35        # 最低可信度，增大数字以提高分析精度，降低数字以覆盖更全面的结果
BUFFER_SEC = 2           # 缓冲秒数，检测到动作后，额外截取之前或之后多少秒的视频
TARGET_CLASSES = [0, 1, 2, 3] # 人、自行车、汽车、摩托车
```
修改源路径、保存路径、并发进程数、跳帧、可信度、目标CLASS等（CLASS请参照YOLO v8模型的说明文档，或直接询问AI你想要检测的物体分别对应的数字），并保存文件。

**注意：Windows“库”内的文件夹名称通常会与实际名称不一致，例如“C:\Users\用户名\Videos”文件夹，在资源管理器中通常直接显示为“视频”。而在配置pipeline.py时，不能直接使用这个名称，应当先点击地址栏，以地址栏显示的实际路径为准。**

6、通过命令提示符（管理员）执行以下命令，开始视频分析：
```
python pipeline.py
```

7、若命令提示符窗口中显示类似以下内容：
```
==========================================
🚀 GPU 管道流引擎已就绪
模式: FFmpeg Pipe + DirectML 推理
==========================================

[*] 启动任务: D02_20251114064101.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114072759.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114081455.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114090151.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114094847.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114103544.mp4 (50.0 FPS)
  > D02_20251114072759.mp4: 已处理 20 秒...
  > D02_20251114064101.mp4: 已处理 20 秒...
  > D02_20251114094847.mp4: 已处理 20 秒...
  > D02_20251114090151.mp4: 已处理 20 秒...
  > D02_20251114081455.mp4: 已处理 20 秒...
  > D02_20251114103544.mp4: 已处理 20 秒...
```
**并且你能够在任务管理器中看到GPU的3D或Compute_0图表有明显的变化、专用GPU内存占用量有所提升，且CPU不是一直跑在100%占用率的话**，证明Direct ML API已经调用成功，并且在尽可能利用你的GPU性能进行分析。

如果你发现显卡占用率没有变化，且CPU爆满，则证明显卡硬件没有被成功调用。pipeline.py理论上已经使用最强硬的手段调用Direct ML了，如果还是掉回CPU运算，则应当考虑GPU是否支持Direct ML API，或是显卡驱动是否过老等。

如果你发现处理速度非常慢（通常以3-5秒处理20秒的视频内容为宜），但GPU也确实被调用了，请尝试调整Num_process、Stride、Img_size的数量。你可以使用AI工具帮你分析你的硬件配置适合什么样的参数。另外，因为默认的6并发进程有时候会对硬盘性能提出要求，故不推荐将视频源目录放在机械硬盘（尤其是5400rpm的笔记本硬盘）下，你可以尝试将文件转移到固态硬盘后再进行分析。

8、每个视频分析完成后，均会在你设置的结果保存路径下生成截取好的视频片段，你可以打开再进行人工分析。此时的视频片段相比原视频已经大幅缩短，可以有效节省你的时间和精力。
