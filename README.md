# 监控摄像头视频画面分析工具
### 写在开头：
**本工具所涉及代码完全使用Gemini AI生成，经反复试错修改后得到当前版本。因本人不具备充足的编程知识，故不能提供详细的技术支持，也不设置任何的著作权声明。任何人无需经过同意，即可随意下载、使用和修改本Repo的代码。**

---

### 本工具的设计目标：
1、在不使用NVIDIA GPU和CUDA的情况下，依赖Direct ML API在Windows环境下实现本地化AI图像分析。本Repo以AMD Radeon RX9070 16GB为例。 **UPDATE：** 新增了完全不需要AI，只通过GPU解码和CPU加减法运算画面变化的方案，以便进一步减少特定场景下的误判、漏判问题。

2、通过多个方案的脚本，批量分析安防监控设备拍摄到的视频文件，从中截取存在人物、车辆活动的片段，并保存到指定目录，以期通过这种方式大幅减少分析监控画面所需的人力和时间成本，并尽可能避免遗漏。

3、借助FFmpeg的强大功能（FFmpeg管道流，Streaming Pipe）暴力解决部分品牌、型号的硬盘录像机所生成的视频文件不规范、导致Windows和部分第三方的视频播放器无法加载缩略图、无法正常打开和解码视频的问题。通过强行读取视频时长、FPS帧率和画面等信息，能够确保即使是不规范的视频文件，也可以正确解码并发送给AI进行分析。同时，在截取片段后，确保保存出来的结果是系统可以直接读取，无需再借助第三方工具进行解码的。

4、尽可能降低部署和运行的成本，并在代码中给足必要的注释，确保新手也能够轻松运行。

5、通过暴力方式强行解决Ultralytics始终倾向于使用CUDA或CPU进行运算，而不去调用Direct ML的问题。

---

### 本工具不适用于以下场景：
1、（仅针对AI方案）使用了NVIDIA GPU的设备。（不强制，即便是英伟达的显卡也可以跑Direct ML，但效率肯定不如专门优化的CUDA。你可以将本repo的链接整个喂给AI，让它帮你生成一个使用CUDA运行的方案。）

2、画面复杂多变、时常有人物车辆等活动的监控视频。因为代码没有划定ROI（感兴趣区域），因此整个视频的画面都会被纳入识别范围。如果监控摄像头位于经常有物体活动的位置，如马路、办公室、超市等，则它会大量截取不相关的片段，使得本工具失去意义。

3、（仅针对AI方案）画面通常静止，但被识别物体时常处于画面中的监控视频。因为AI模型主要用于识别特定的物体，而代码的逻辑是只要识别出来就截取，因此即便是在画面中静止了很久的物体，例如人、汽车、摩托车、自行车，甚至是印有人像的海报等，也会被截取出来。因此AI版本的脚本不适用于长期存在以上物体的场景，例如车库、停车场等。此时，你应当考虑使用motion.py，即仅计算画面变化的方案。

3、完全不规范甚至加密的监控视频文件。极个别监控录像产品会使用私有格式编码和保存，若导出的视频文件不为FFmpeg能够直接解码的常见格式，例如mp4、avi、mkv、mov、flv等，则本工具将完全不可用。你需要想办法将监控视频以常见的视频格式保存出来，再使用本工具进行分析。

---

### 推荐配置：
CPU：2014年之后的主流四核或以上CPU，至少能够确保软解1080P视频流畅的型号

RAM：16GB或以上

GPU：（AI方案）支持Direct ML API、独立显存大于等于4GB的显卡；（非AI方案）支持视频硬件解码的显卡

硬盘：存放监控视频的硬盘推荐使用SSD固态硬盘（使用了USB3.0或以上的移动固态硬盘，或固态硬盘+USB3.0硬盘盒的方案也可），以确保并发任务流畅完成；保存截取片段的硬盘无要求

操作系统：Windows 10或以上，支持Python 3.11+运行

---

### 更新日志：
2025/12/23 鉴于AI模型会无差别识别目标物体，导致脚本大量截取无用的静止片段，新增了非AI的motion.py方案，使用CPU加减运算直接识别存在变化的画面，完全忽略静止15秒以上的画面，避免浪费大量时间和消耗无用算力，覆盖更全面的使用场景。

2025/12/22 首次发布。

---

### 部署方法（AI分析）：
1、前往 https://www.python.org/downloads/windows/ 下载并安装Windows版本的**Python 3.11.0**。不建议使用其他版本，否则安装依赖时极有可能会报错。若你的系统中已经安装了高版本的Python，请卸载或寻找指定Python版本运行的方式。

2、打开命令提示符（管理员），输入以下代码安装依赖：
```
pip install ultralytics onnxruntime-directml pandas moviepy
```

3、下载本Repo的exportmodel.py文件，通过命令提示符（管理员），执行以下命令：
```
python exportmodel.py
```
此时脚本会在C:\Users\用户名目录下生成yolov8n.pt和转换后的yolov8n.onnx模型文件。

4、下载本Repo的check.py文件，通过命令提示符（管理员），执行以下命令：
```
python check.py
```
若返回的结果中包含“DmlExecutionProvider”，则证明能够调用GPU进行处理。

5、下载本Repo的pipeline.py文件，使用记事本或其他代码编辑器打开并编辑部分内容：
```
# --- 核心参数配置 ---
SOURCE_DIR = r"H:\Videos"  # 你的视频源路径
SAVE_DIR = r"E:\process\clips"      # 结果保存路径
MODEL_PATH = "yolov8n.onnx"
NUM_PROCESSES = 6        # 并发进程数，5700X3D 建议 4-6 个进程，与下方STRIDE配合修改，STRIDE越大，运算压力越小，并发数可以越多
STRIDE = 10              # 跳帧数量，每隔多少帧分析一次，可适当增加以提高解析速度
IMG_SIZE = 1024          # 统一推理分辨率，中高端GPU推荐至少1024分辨率以提高分析精度
CONF_LEVEL = 0.35        # 最低可信度，增大数字以提高分析精度，降低数字以覆盖更全面的结果
BUFFER_SEC = 2           # 缓冲秒数，检测到动作后，额外截取之前或之后多少秒的视频
TARGET_CLASSES = [0, 1, 2, 3] # 人、自行车、汽车、摩托车
```
修改源路径、保存路径、并发进程数、跳帧、可信度、目标CLASS等（CLASS请参照YOLO v8模型的说明文档，或直接询问AI你想要检测的物体分别对应的数字），并保存文件。

**注意：Windows“库”内的文件夹名称通常会与实际名称不一致，例如“C:\Users\用户名\Videos”文件夹，在资源管理器中通常直接显示为“视频”。而在配置pipeline.py时，不能直接使用这个名称，应当先点击地址栏，以地址栏显示的实际路径为准。**

6、通过命令提示符（管理员）执行以下命令，开始视频分析：
```
python pipeline.py
```

7、若命令提示符窗口中显示类似以下内容：
```
==========================================
🚀 GPU 管道流引擎已就绪
模式: FFmpeg Pipe + DirectML 推理
==========================================

[*] 启动任务: D02_20251114064101.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114072759.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114081455.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114090151.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114094847.mp4 (50.0 FPS)
[*] 启动任务: D02_20251114103544.mp4 (50.0 FPS)
  > D02_20251114072759.mp4: 已处理 20 秒...
  > D02_20251114064101.mp4: 已处理 20 秒...
  > D02_20251114094847.mp4: 已处理 20 秒...
  > D02_20251114090151.mp4: 已处理 20 秒...
  > D02_20251114081455.mp4: 已处理 20 秒...
  > D02_20251114103544.mp4: 已处理 20 秒...
```
**并且你能够在任务管理器中看到GPU的3D或Compute_0图表有明显的变化、专用GPU内存占用量有所提升，且CPU不是一直跑在100%占用率的话**，证明Direct ML API已经调用成功，并且在尽可能利用你的GPU性能进行分析。

如果你发现显卡占用率没有变化，且CPU爆满，则证明显卡硬件没有被成功调用。pipeline.py理论上已经使用最强硬的手段调用Direct ML了，如果还是掉回CPU运算，则应当考虑GPU是否支持Direct ML API，或是显卡驱动是否过老等。

如果你发现处理速度非常慢（通常以3-5秒处理20秒的视频内容为宜），但GPU也确实被调用了，请尝试调整Num_process、Stride、Img_size的数量。你可以使用AI工具帮你分析你的硬件配置适合什么样的参数。另外，因为默认的6并发进程有时候会对硬盘性能提出要求，故不推荐将视频源目录放在机械硬盘（尤其是5400rpm的笔记本硬盘）下，你可以尝试将文件转移到固态硬盘后再进行分析。

8、每个视频分析完成后，均会在你设置的结果保存路径下生成截取好的视频片段，你可以打开再进行人工分析。此时的视频片段相比原视频已经大幅缩短，可以有效节省你的时间和精力。

---

### 部署方法（非AI分析）：

1、前往 https://www.python.org/downloads/windows/ 下载并安装Windows版本的Python，版本号通常不做限制，但如果你希望一并尝试AI方案的话，请下载3.11.0。

2、打开命令提示符（管理员），输入以下代码安装依赖：
```
pip install opencv-python numpy
```

3、下载本Repo中的motion.py，用记事本或其他代码编辑器打开，编辑以下部分：
```
# --- 1. 核心参数配置 ---
SOURCE_DIR = r"H:\Videos" # 视频源目录
SAVE_DIR = r"E:\process\motion" # 导出剪辑后视频的目录
NUM_PROCESSES = 6        # 并发任务数，数量越高理论速度越快，但CPU、GPU和硬盘读写消耗越高
STRIDE = 10               # 跳帧：每 10 帧检测一次。数值越大处理越快，数值越小越灵敏
BUFFER_SEC = 3           # 剪辑前后保留的缓冲时间（秒）
MIN_MOTION_AREA = 500    # 运动阈值：变化像素点超过此值视为有物体动（夜视建议 500-800）
STOP_AFTER_SILENT = 15   # 画面无变化超过 15 秒则自动断开剪辑
```
请参照注释自行修改。

4、前往 https://www.gyan.dev/ffmpeg/builds/#release-builds ，下载ffmpeg-release-full，并将其中的ffmpeg.exe和ffprobe.exe解压到和motion.py脚本相同的位置。

5、打开命令提示符（管理员），执行以下命令：
```
python motion.py
```

6、静静等待处理完成即可。每个视频分析完成后，均会将剪辑的结果保存在你指定的目录下，你可以打开再进行人工分析。实际处理速度主要与CPU性能相关，核心数越多、IPC越高的CPU处理越快。
