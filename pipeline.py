import os
import subprocess
import multiprocessing
import numpy as np
from concurrent.futures import ProcessPoolExecutor, as_completed
import onnxruntime as ort

# --- æ ¸å¿ƒå‚æ•°é…ç½® ---
SOURCE_DIR = r"H:\Videos"  # ä½ çš„è§†é¢‘æºè·¯å¾„
SAVE_DIR = r"E:\process\clips"      # ç»“æœä¿å­˜è·¯å¾„
MODEL_PATH = "yolov8n.onnx"
NUM_PROCESSES = 6        # å¹¶å‘è¿›ç¨‹æ•°ï¼Œ5700X3D å»ºè®® 4-6 ä¸ªè¿›ç¨‹ï¼Œä¸ä¸‹æ–¹STRIDEé…åˆä¿®æ”¹ï¼ŒSTRIDEè¶Šå¤§ï¼Œè¿ç®—å‹åŠ›è¶Šå°ï¼Œå¹¶å‘æ•°å¯ä»¥è¶Šå¤š
STRIDE = 10              # è·³å¸§æ•°é‡ï¼Œæ¯éš”å¤šå°‘å¸§åˆ†æä¸€æ¬¡ï¼Œå¯é€‚å½“å¢åŠ ä»¥æé«˜è§£æé€Ÿåº¦
IMG_SIZE = 1024          # ç»Ÿä¸€æ¨ç†åˆ†è¾¨ç‡ï¼Œä¸­é«˜ç«¯GPUæ¨èè‡³å°‘1024åˆ†è¾¨ç‡ä»¥æé«˜åˆ†æç²¾åº¦
CONF_LEVEL = 0.35        # æœ€ä½å¯ä¿¡åº¦ï¼Œå¢å¤§æ•°å­—ä»¥æé«˜åˆ†æç²¾åº¦ï¼Œé™ä½æ•°å­—ä»¥è¦†ç›–æ›´å…¨é¢çš„ç»“æœ
BUFFER_SEC = 2           # ç¼“å†²ç§’æ•°ï¼Œæ£€æµ‹åˆ°åŠ¨ä½œåï¼Œé¢å¤–æˆªå–ä¹‹å‰æˆ–ä¹‹åå¤šå°‘ç§’çš„è§†é¢‘
TARGET_CLASSES = [0, 1, 2, 3] # äººã€è‡ªè¡Œè½¦ã€æ±½è½¦ã€æ‘©æ‰˜è½¦

def get_video_info(path):
    """ä½¿ç”¨ ffprobe è·å–å¸§ç‡å’Œæ—¶é•¿ï¼Œå³ä½¿ç´¢å¼•æŸåä¹Ÿèƒ½å°è¯•ä¼°ç®—"""
    cmd = [
        'ffprobe', '-v', 'error', '-select_streams', 'v:0',
        '-show_entries', 'stream=avg_frame_rate,duration',
        '-of', 'default=noprint_wrappers=1:nokey=1', path
    ]
    try:
        res = subprocess.run(cmd, capture_output=True, text=True, check=True)
        lines = res.stdout.strip().split('\n')
        fps = eval(lines[0]) if '/' in lines[0] else float(lines[0])
        duration = float(lines[1]) if len(lines) > 1 else 2700.0
        return fps, duration
    except:
        return 25.0, 2700.0 # é»˜è®¤ 25å¸§ï¼Œ45åˆ†é’Ÿå…œåº•

def process_single_video(video_name):
    video_path = os.path.join(SOURCE_DIR, video_name)
    save_name_base = os.path.splitext(video_name)[0]
    
    fps, duration = get_video_info(video_path)
    print(f"[*] å¯åŠ¨ä»»åŠ¡: {video_name} ({fps} FPS)")

    # 1. å¯åŠ¨ FFmpeg ç®¡é“æ¨¡å¼
    # -vf fps={fps/STRIDE}: è®© FFmpeg å¸®æˆ‘ä»¬åœ¨è§£ç å±‚è·³å¸§ï¼Œæå¤§å‡è½» Python å‹åŠ›
    # -s {IMG_SIZE}x{IMG_SIZE}: å¼ºåˆ¶ç¼©æ”¾åˆ°æ¨ç†å°ºå¯¸
    # -f image2pipe: è¾“å‡ºåŸå§‹å›¾åƒæµ
    ffmpeg_cmd = [
        'ffmpeg', 
        '-loglevel', 'error',
        '-hwaccel', 'd3d11va',        # 1. å¼€å¯ D3D11 ç¡¬ä»¶åŠ é€Ÿæ¥å£
        '-hwaccel_device', '0',        # 2. æŒ‡å®šç¬¬ä¸€å—æ˜¾å¡
        '-i', video_path,
        '-vf', f'fps={fps/STRIDE},scale={IMG_SIZE}:{IMG_SIZE}', # ç¡¬ä»¶å±‚ç¼©æ”¾
        '-f', 'image2pipe', 
        '-pix_fmt', 'bgr24', 
        '-vcodec', 'rawvideo', 
        '-'
    ]
    
    # 2. åˆå§‹åŒ– DirectML
    opts = ort.SessionOptions()
    session = ort.InferenceSession(
        MODEL_PATH, 
        sess_options=opts, 
        providers=[('DmlExecutionProvider', {'device_id': 0}), 'CPUExecutionProvider']
    )
    input_name = session.get_inputs()[0].name

    active_seconds = set()
    pipe = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, bufsize=10**8)
    
    # æ¯å¸§çš„æ•°æ®å¤§å° (1024*1024*3 å­—èŠ‚)
    frame_size = IMG_SIZE * IMG_SIZE * 3
    count = 0

    try:
        while True:
            # ç›´æ¥ä»ç®¡é“è¯»å–åŸå§‹å­—èŠ‚
            raw_frame = pipe.stdout.read(frame_size)
            if not raw_frame: break
            
            # å¿«é€Ÿè½¬æ¢ä¸ºå¼ é‡
            frame = np.frombuffer(raw_frame, dtype=np.uint8).reshape((3, IMG_SIZE, IMG_SIZE))
            img = frame.astype(np.float32) / 255.0
            img = np.expand_dims(img, axis=0)

            # RX 9070 æ¨ç†
            outputs = session.run(None, {input_name: img})
            preds = np.squeeze(outputs[0])
            
            # ç®€å•è§£æé€»è¾‘ (YOLOv8 è¾“å‡º [84, 21504])
            scores = np.max(preds[4:, :], axis=0)
            class_ids = np.argmax(preds[4:, :], axis=0)
            
            if np.any((scores > CONF_LEVEL) & np.isin(class_ids, TARGET_CLASSES)):
                current_sec = (count * STRIDE) / fps
                active_seconds.add(int(current_sec))
            
            count += 1
            if count % 100 == 0:
                print(f"  > {video_name}: å·²å¤„ç† {int((count*STRIDE)/fps)} ç§’...")

        pipe.stdout.close()
        pipe.wait()

        if not active_seconds:
            return f"[-] æœªå‘ç°ç›®æ ‡: {video_name}"

        # 3. åˆå¹¶ç‰‡æ®µå¹¶å‰ªè¾‘
        sorted_secs = sorted(list(active_seconds))
        segments = []
        if sorted_secs:
            start, end = sorted_secs[0], sorted_secs[0]
            for s in sorted_secs[1:]:
                if s <= end + BUFFER_SEC + 1:
                    end = s
                else:
                    segments.append((max(0, start-BUFFER_SEC), min(duration, end+BUFFER_SEC)))
                    start, end = s, s
            segments.append((max(0, start-BUFFER_SEC), min(duration, end+BUFFER_SEC)))

        # 4. ä¿®å¤å¼å‰ªè¾‘å¯¼å‡º
        for i, (ts, te) in enumerate(segments):
            out_file = os.path.join(SAVE_DIR, f"{save_name_base}_part{i}.mp4")
            # +genpts å’Œ -tag:v hvc1 è§£å†³ Win11 ä¸è¯†åˆ«é—®é¢˜
            subprocess.run([
                'ffmpeg', '-y', '-loglevel', 'error', '-fflags', '+genpts',
                '-ss', str(round(ts, 2)), '-t', str(round(te-ts, 2)),
                '-i', video_path, '-c', 'copy', '-tag:v', 'hvc1', '-an', out_file
            ])
        
        return f"[+] æˆåŠŸ: {video_name} (å¯¼å‡º {len(segments)} æ®µ)"

    except Exception as e:
        if pipe: pipe.terminate()
        return f"[!] æŠ¥é”™: {video_name} -> {str(e)}"

def main():
    if not os.path.exists(SAVE_DIR): os.makedirs(SAVE_DIR)
    files = [f for f in os.listdir(SOURCE_DIR) if f.endswith(('.mp4', '.mkv', '.avi'))]
    
    print(f"==========================================")
    print(f"ğŸš€ GPU ç®¡é“æµå¼•æ“å·²å°±ç»ª")
    print(f"æ¨¡å¼: FFmpeg Pipe + DirectML æ¨ç†")
    print(f"==========================================\n")

    with ProcessPoolExecutor(max_workers=NUM_PROCESSES) as executor:
        futures = {executor.submit(process_single_video, f): f for f in files}
        for future in as_completed(futures):
            print(future.result())

if __name__ == "__main__":
    multiprocessing.freeze_support()
    main()
